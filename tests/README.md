# ðŸ§ª Akira Traders - Test Suite

Suite completa de tests que valida el cumplimiento del cÃ³digo con la documentaciÃ³n y especificaciones del proyecto.

## ðŸ“‹ Contenido

### **Compliance Tests** (`compliance/`)
Tests que validan que el cÃ³digo implementado cumple con la documentaciÃ³n:

- `test_documentation_compliance.py` - Verifica cumplimiento con ARCHITECTURE.md y methodology.md
  - âœ… Perfiles de riesgo definidos
  - âœ… Estructura del proyecto
  - âœ… Endpoints de API
  - âœ… Sistema de scoring
  - âœ… Calidad de documentaciÃ³n

### **Unit Tests** (`unit/`)
Tests unitarios para componentes individuales:

- `test_validation.py` - ValidaciÃ³n de schemas y datos
  - âœ… Estructura de evaluaciones
  - âœ… Rangos de mÃ©tricas
  - âœ… Perfiles de riesgo
  - âœ… Integridad de datos

- `test_scripts.py` - Tests de scripts Python
  - âœ… Existencia de scripts
  - âœ… Funcionalidad bÃ¡sica
  - âœ… Dependencias

### **Integration Tests** (`integration/`)
Tests de integraciÃ³n entre componentes:

- `test_backend_api.py` - Tests del servidor Flask
  - âœ… Endpoints de API
  - âœ… Manejo de errores
  - âœ… CORS
  - âœ… CRUD de evaluaciones

## ðŸš€ Uso

### Ejecutar todos los tests

```bash
python run_tests.py
```

### Ejecutar solo tests de cumplimiento

```bash
python run_tests.py --compliance
```

### Ejecutar tests con cobertura

```bash
python run_tests.py --coverage
```

### Ejecutar tests especÃ­ficos

```bash
# Solo validaciÃ³n
python run_tests.py --validation

# Solo integraciÃ³n
python run_tests.py --integration

# Solo unitarios
python run_tests.py --unit
```

### Generar reporte XML

```bash
python run_tests.py --report
```

## ðŸ“Š CategorÃ­as de Tests

### 1. **Compliance** (Cumplimiento)
Valida que el cÃ³digo cumpla con las especificaciones documentadas:

```bash
pytest -m compliance -v
```

Tests incluidos:
- Perfiles de riesgo segÃºn methodology.md
- Estructura del proyecto segÃºn ARCHITECTURE.md
- Endpoints de API segÃºn especificaciÃ³n
- Sistema de scoring documentado

### 2. **Validation** (ValidaciÃ³n)
Valida integridad y correctitud de datos:

```bash
pytest -m validation -v
```

Tests incluidos:
- Schemas JSON vÃ¡lidos
- Rangos de mÃ©tricas correctos
- Tipos de datos apropiados
- Campos requeridos presentes

### 3. **Integration** (IntegraciÃ³n)
Valida integraciÃ³n entre componentes:

```bash
pytest -m integration -v
```

Tests incluidos:
- Endpoints de API funcionales
- ComunicaciÃ³n backend-scripts
- Flujo de datos completo

### 4. **Unit** (Unitarios)
Tests de componentes individuales:

```bash
pytest -m unit -v
```

Tests incluidos:
- Funciones de cÃ¡lculo
- Validadores
- Utilidades

## ðŸ› ï¸ ConfiguraciÃ³n

### pytest.ini
ConfiguraciÃ³n principal de pytest:

```ini
[pytest]
testpaths = tests
python_files = test_*.py
markers =
    compliance: Tests de cumplimiento
    validation: Tests de validaciÃ³n
    integration: Tests de integraciÃ³n
    unit: Tests unitarios
```

### conftest.py
Fixtures globales disponibles en todos los tests:

- `base_dir` - Directorio base del proyecto
- `scripts_dir` - Directorio de scripts
- `backend_dir` - Directorio del backend
- `docs_dir` - Directorio de documentaciÃ³n
- `evaluations_dir` - Directorio de evaluaciones

## ðŸ“ˆ Cobertura de CÃ³digo

Para generar reporte de cobertura:

```bash
python run_tests.py --coverage
```

Esto generarÃ¡:
- Reporte en consola
- Reporte HTML en `htmlcov/`

Abrir reporte HTML:

```bash
# macOS
open htmlcov/index.html

# Linux
xdg-open htmlcov/index.html

# Windows
start htmlcov/index.html
```

## ðŸ” Tests EspecÃ­ficos

### Ejecutar un archivo de test especÃ­fico

```bash
pytest tests/compliance/test_documentation_compliance.py -v
```

### Ejecutar una clase de tests especÃ­fica

```bash
pytest tests/unit/test_validation.py::TestTraderEvaluationSchema -v
```

### Ejecutar un test individual

```bash
pytest tests/unit/test_validation.py::TestTraderEvaluationSchema::test_valid_evaluation_structure -v
```

## ðŸ“ Agregar Nuevos Tests

### 1. Crear archivo de test

```python
# tests/unit/test_new_feature.py

import pytest

class TestNewFeature:
    """Tests para nueva funcionalidad"""

    def test_something(self):
        """DescripciÃ³n del test"""
        assert True
```

### 2. Marcar con categorÃ­a

```python
@pytest.mark.unit
def test_unit_feature():
    assert True

@pytest.mark.integration
def test_integration_feature():
    assert True
```

### 3. Usar fixtures

```python
def test_with_fixture(base_dir):
    """Usa fixture global"""
    assert base_dir.exists()
```

## ðŸŽ¯ Objetivos de Testing

### Cobertura MÃ­nima
- **Compliance**: 100% (toda la documentaciÃ³n debe estar validada)
- **Scripts**: 80% (funciones crÃ­ticas cubiertas)
- **Backend**: 70% (endpoints principales cubiertos)

### Tipos de Tests

1. **Smoke Tests**: Verifican que el sistema arranca
2. **Functional Tests**: Verifican funcionalidad especÃ­fica
3. **Compliance Tests**: Verifican cumplimiento con specs
4. **Integration Tests**: Verifican integraciÃ³n entre componentes

## ðŸ› Troubleshooting

### Error: ModuleNotFoundError

```bash
# AsegÃºrate de que el directorio de scripts estÃ© en el path
export PYTHONPATH="${PYTHONPATH}:$(pwd)/scripts"
```

### Error: No module named 'pytest'

```bash
# Instalar pytest
pip install pytest pytest-cov
```

### Tests muy lentos

```bash
# Omitir tests lentos
pytest -m "not slow"
```

### Ver output detallado

```bash
# Modo extra verbose con output completo
pytest -vv -s
```

## ðŸ“š Recursos

- [pytest Documentation](https://docs.pytest.org/)
- [pytest-cov](https://pytest-cov.readthedocs.io/)
- [Testing Best Practices](https://docs.python-guide.org/writing/tests/)

## ðŸ¤ Contribuir

Al agregar cÃ³digo nuevo:

1. âœ… Escribir tests para nueva funcionalidad
2. âœ… Asegurar que todos los tests pasen
3. âœ… Mantener cobertura > 70%
4. âœ… Documentar tests complejos

## ðŸ“„ Licencia

MIT License - Ver [LICENSE](../LICENSE) para detalles.
